{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共选取六大类因子中的106个特征值+10个风险因子，使用LightGBM来进行2分类概率预测（分为两种标签值构造）\n",
    "二分类：\n",
    "1.按照股票涨跌幅排序，收益前T%标记为1， 其余标记为0\n",
    "2.按照股票涨跌幅排序，收益前T%标记为1， 后T%标记为-1，中间为0（训练集只用“1，-1”类，删除“0”类，测试集用全部）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import daolib.dao as dao\n",
    "import daolib.dso as dso\n",
    "import util.sectool as sectool\n",
    "import util.operatetool as optool\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_price_df = dao.get_security_info('stock_price_info')\n",
    "all_stock_list = stock_price_df.index.get_level_values(0).drop_duplicates().tolist()\n",
    "#六大类因子106个\n",
    "pricevol_factors_list = ['pv_clo_ratemean_1m', 'pv_clo_ratemean_3m', 'pv_clo_ratemean_6m', 'pv_corr_clo_turn_1m',\n",
    "                        'pv_corr_clo_turn_3m',  'pv_max_ret_1m', 'pv_max_ret_3m', 'pv_cgo_3m', 'pv_iv_capm_hs_3m', 'pv_iv_capm_r2_hs_3m', 'pv_iv_capm_r2_zz_3m',\n",
    "                        'pv_iv_capm_zz_3m', 'pv_iv_ff_hs_3m', 'pv_iv_ff_r2_hs_3m', 'pv_iv_ff_r2_zz_3m', 'pv_iv_ff_zz_3m',\n",
    "                        'pv_cgo_1m', 'pv_cgo_6m', 'pv_iv_capm_hs_1m', 'pv_iv_capm_r2_hs_1m', 'pv_iv_capm_r2_zz_1m',\n",
    "                        'pv_iv_capm_zz_1m', 'pv_iv_ff_hs_1m', 'pv_iv_ff_r2_hs_1m', 'pv_iv_ff_r2_zz_1m', 'pv_iv_ff_zz_1m']\n",
    "\n",
    "mom_factors_list = ['mm_mom_1m', 'mm_mom_1m_weighted', 'mm_mom_1m_weightedexp',\n",
    "                    'mm_mom_1y_weightedexp', 'mm_mom_3m', 'mm_mom_3m_weighted', 'mm_mom_3m_weightedexp',\n",
    "                     'mm_mom_6m_weighted', 'mm_mom_6m_weightedexp']\n",
    "\n",
    "emotion_factors_list = ['em_cov_volume_1m','em_cov_volume_3m','em_ret_amt_1m',\\\n",
    "                        'em_ret_amt_3m', 'em_ret_amt_6m','em_sl_volume_1m','em_turn_cov_1m',\\\n",
    "                        'em_turn_cov_3m','em_turn_mean_1m', 'em_turn_mean_3m','em_turn_mean_6m',\\\n",
    "                       'em_turn_std_1m', 'em_turn_std_3m','em_turn_std_6m', 'em_turn_stdrate_1m','em_turn_stdrate_3m',\\\n",
    "                       ]\n",
    "\n",
    "finance_factors_list = ['fn_gross_profit2assets',  'fn_qfa_ebit', 'fn_qfa_ebit2assets',\n",
    "                        'fn_qfa_ni_from_operating', 'fn_qfa_ni_from_operating2assets', 'fn_qfa_np',\n",
    "                        'fn_qfa_profit_before_tax2assets', 'fn_qfa_roa', 'fn_qfa_roa_deducted', 'fn_qfa_roe',\n",
    "                        'fn_qfa_roe_deducted', 'fn_qfa_total_income2assets', 'fn_qfa_tot_income_indus']\n",
    "\n",
    "growth_factors_list = ['gw_advantage', 'gw_chg_gpmargin_ttm', 'gw_growth_qfa_yoy_gr',\n",
    "                       'gw_qfa_np_enhance', 'gw_qfa_yoyop', 'gw_qfa_yoy_gr', 'gw_qfa_yoy_or', 'gw_roe_chg',\n",
    "                       'gw_roe_deducted_chg', 'gw_roe_deducted_enhance', 'gw_roe_deducted_yoy', 'gw_roe_enhance',\n",
    "                       'gw_roe_yoy', 'gw_trend', 'gw_yoy_qfa_deductedprofit', 'gw_yoy_qfa_np_belongto_parcomsh',\n",
    "                       'gw_yoy_qfa_roe_deducted']\n",
    "\n",
    "valuation_factors_list = [  'val_ep_de_qfa', 'val_ep_de_sq',\n",
    "                          'val_ep_de_ttm', 'val_ep_qfa', 'val_ep_sq', 'val_pge_de',\n",
    "                          'val_equity_mkt']\n",
    "\n",
    "estimate_factors_list = ['et_eps_ftm_mom3', 'et_ep_ftm', 'et_ep_ftm_mom1', 'et_ep_ftm_mom3', 'et_ep_ftm_mom6',\n",
    "                         'et_ep_fy1', 'et_ep_fy2', 'et_gr_ftm_mom3', 'et_np_ftm', 'et_np_ftm_mom3', 'et_np_fy1',\n",
    "                         'et_np_fy2', 'et_peg_ftm', 'et_roe_ftm']\n",
    "\n",
    "alpha191_factors_list =['alpha101_013_data','alpha101_015_data','alpha101_016_data','alpha101_026_data',\n",
    "                        'alpha101_040_data','alpha101_044_data','alpha101_050_data','alpha101_055_data',\n",
    "                        'alpha101_064_data', 'alpha101_074_data' ,'alpha101_075_data','alpha101_099_data',\n",
    "                        'alpha191_001_data','alpha191_005_data','alpha191_007_data','alpha191_009_data','alpha191_017_data',\n",
    "                        'alpha191_022_data','alpha191_030_data','alpha191_031_data','alpha191_032_data','alpha191_036_data',\n",
    "                        'alpha191_042_data','alpha191_046_data','alpha191_074_data','alpha191_090_data','alpha191_092_data',\n",
    "                        'alpha191_101_data','alpha191_105_data','alpha191_112_data','alpha191_118_data','alpha191_123_data',\n",
    "                        'alpha191_124_data','alpha191_139_data','alpha191_173_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#十个风险因子\n",
    "\n",
    "#股票上市状态(只选择为0的值，不为0的值为异常值)\n",
    "price_df=dao.get_security_info('stock_price_info')\n",
    "trade_status_df=price_df.xs('trade_status',level=1)\n",
    "\n",
    "def risk_factor(alpha_factor_series):\n",
    "    alpha_factor_series['beta'] = dao.get_style_risk_factor('risk_beta', 'def')\n",
    "    alpha_factor_series['mv'] = dao.get_style_risk_factor('risk_mv', 'def')\n",
    "    alpha_factor_series['vol'] = dao.get_style_risk_factor('risk_vol', 'def')\n",
    "    alpha_factor_series['liq'] = dao.get_style_risk_factor('risk_liq', 'def')\n",
    "    alpha_factor_series['ey'] = dao.get_style_risk_factor('risk_ey', 'def')\n",
    "    alpha_factor_series['bp'] = dao.get_style_risk_factor('risk_bp', 'def')\n",
    "    alpha_factor_series['mom'] = dao.get_style_risk_factor('risk_mom', 'def')\n",
    "    alpha_factor_series['lev'] = dao.get_style_risk_factor('risk_lev', 'def')\n",
    "    alpha_factor_series['nlmv'] = dao.get_style_risk_factor('risk_nlmv', 'def')\n",
    "    alpha_factor_series['gro'] = dao.get_style_risk_factor('risk_gro', 'def')\n",
    "    alpha_factor_series['trade_status'] = trade_status_df\n",
    "    return alpha_factor_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_factor_data(factors_name_list, trade_date_20d_series):\n",
    "    compound_factor_dict = {}\n",
    "    alpha_factor_series = pd.Series()\n",
    "    for compound_name in factors_name_list[:]:\n",
    "        pro_factor_path = \"D:\\\\Data\\\\factors\\\\\" + compound_name + '\\\\'\n",
    "        #alpha_factor_series = pd.Series()\n",
    "        factor_list = globals().get(compound_name + '_factors_list')\n",
    "        for factor_name in factor_list:\n",
    "#             print('读取 ', factor_name)\n",
    "            data_df = pd.read_pickle(pro_factor_path + factor_name)\n",
    "            begin_date = max(data_df.columns[0], trade_date_20d_series[0])\n",
    "            trade_date_series = trade_date_20d_series[trade_date_20d_series >= begin_date]\n",
    "            alpha_factor_series.loc[factor_name] = data_df.loc[:, trade_date_series]\n",
    "    #alpha_factor_df = ftool.factor_class_generate(alpha_factor_series)\n",
    "        #compound_factor_dict[compound_name] = alpha_factor_df\n",
    "    return alpha_factor_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2007, 1, 1)\n",
    "end_date = dt.datetime(2018,9,1)\n",
    "factor_name_list = ['emotion', 'pricevol', 'mom', 'finance', 'valuation', 'alpha191']  #growth\n",
    "\n",
    "#月频数据\n",
    "trade_date_m_series = pd.Series( dso.get_trade_date(start_date=start_date, end_date=end_date, period='m') )\n",
    "month_list = [date for date in trade_date_m_series if dt.datetime(2009,10,1)<date and date < dt.datetime(2018,11,1) ]\n",
    "month_alpha_factor_series = read_factor_data(factors_name_list=factor_name_list, trade_date_20d_series=trade_date_m_series)\n",
    "month_alpha_factor_series=risk_factor(month_alpha_factor_series)\n",
    "\n",
    "#周频数据\n",
    "trade_date_w_series = pd.Series( dso.get_trade_date(start_date=start_date, end_date=end_date, period='w') )\n",
    "week_list = [date for date in trade_date_w_series if dt.datetime(2009,10,20)<date and date < dt.datetime(2018,11,1) ]\n",
    "week_alpha_factor_series = read_factor_data(factors_name_list=factor_name_list, trade_date_20d_series=trade_date_w_series)\n",
    "week_alpha_factor_series=risk_factor(week_alpha_factor_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将上面构造好的数据保存，方便利用\n",
    "month_alpha_factor_series.to_pickle(\"./factor_test_data/LightGBM_allfactor2/month_alpha_factor_series\")\n",
    "week_alpha_factor_series.to_pickle(\"./factor_test_data/LightGBM_allfactor2/week_alpha_factor_series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值处理（一种做处理，一种不作处理，最好不做处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_month_alpha_factor_series=nonefill(month_alpha_factor_series,month_list)  #周频数据\n",
    "fill_week_alpha_factor_series=nonefill(week_alpha_factor_series,week_list)  #周频数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 月频数据(二分类，按照30%和40%划分标签值)\n",
    "Mfactor0_lgb4,Mfactor1_lgb4,Mtest_accuracy_lgb4,Mtrain_accuracy_lgb4=predict_probo_class(month_alpha_factor_series,model_lgb,12,month_list,0.4,-1)\n",
    "Mfactor0_lgb3,Mfactor1_lgb3,Mtest_accuracy_lgb3,Mtrain_accuracy_lgb3=predict_probo_class(month_alpha_factor_series,model_lgb,12,month_list,0.3,-1)\n",
    "\n",
    "Mfactor0_xgb4,Mfactor1_xgb4,Mtest_accuracy_xgb4,Mtrain_accuracy_xgb4=predict_probo_class(month_alpha_factor_series,model_xgb,12,month_list,0.4,-1)\n",
    "Mfactor0_xgb3,Mfactor1_xgb3,Mtest_accuracy_xgb3,Mtrain_accuracy_xgb3=predict_probo_class(month_alpha_factor_series,model_xgb,12,month_list,0.3,-1)\n",
    "                                                                                         \n",
    "Mfactor0_GBoost4,Mfactor1_GBoost4,Mtest_accuracy_GBoost4,Mtrain_accuracy_GBoost4=predict_probo_class(month_alpha_factor_series,GBoost,12,month_list,0.4,-1)\n",
    "Mfactor0_GBoost3,Mfactor1_GBoost3,Mtest_accuracy_GBoost3,Mtrain_accuracy_GBoost3=predict_probo_class(month_alpha_factor_series,GBoost,12,month_list,0.3,-1)\n",
    "\n",
    "Mfactor0_RF4,Mfactor1_RF4,Mtest_accuracy_RF4,Mtrain_accuracy_RF4=predict_probo_class(month_alpha_factor_series,RF,12,month_list,0.4,-1)\n",
    "Mfactor0_RF3,Mfactor1_RF3,Mtest_accuracy_RF3,Mtrain_accuracy_RF3=predict_probo_class(month_alpha_factor_series,RF,12,month_list,0.3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#周频数据(二分类，按照30%和40%划分标签值)\n",
    "Wfactor0_lgb3,Wfactor1_lgb3,Wtest_accuracy_lgb3,Wtrain_accuracy_lgb3=predict_probo_class(week_alpha_factor_series,model_lgb,48,week_list,0.4,-1)\n",
    "Wfactor0_lgb4,Wfactor1_lgb4,Wtest_accuracy_lgb4,Wtrain_accuracy_lgb4=predict_probo_class(week_alpha_factor_series,model_lgb,48,week_list,0.3,-1)\n",
    "\n",
    "Wfactor0_xgb4,Wfactor1_xgb4,Wtest_accuracy_xgb4,Wtrain_accuracy_xgb4=predict_probo_class(week_alpha_factor_series,model_xgb,12,week_list,0.4,-1)\n",
    "Wfactor0_xgb3,Wfactor1_xgb3,Wtest_accuracy_xgb3,Wtrain_accuracy_xgb3=predict_probo_class(week_alpha_factor_series,model_xgb,12,week_list,0.3,-1)\n",
    "                                                                                         \n",
    "Wfactor0_GBoost4,Wfactor1_GBoost4,Wtest_accuracy_GBoost4,Wtrain_accuracy_GBoost4=predict_probo_class(week_alpha_factor_series,GBoost,12,week_list,0.4,-1)\n",
    "Wfactor0_GBoost3,Wfactor1_GBoost3,Wtest_accuracy_GBoost3,Wtrain_accuracy_GBoost3=predict_probo_class(week_alpha_factor_series,GBoost,12,week_list,0.3,-1)\n",
    "\n",
    "Wfactor0_RF4,Wfactor1_RF4,Wtest_accuracy_RF4,Wtrain_accuracy_RF4=predict_probo_class(week_alpha_factor_series,RF,12,week_list,0.4,-1)\n",
    "Wfactor0_RF3,Wfactor1_RF3,Wtest_accuracy_RF3,Wtrain_accuracy_RF3=predict_probo_class(week_alpha_factor_series,RF,12,week_list,0.3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测准确率分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accu_score(Wtest_accuracy_lgb3,\"score30_train\")\n",
    "accu_score(Wtrain_accuracy_lgb3,\"score30_train\")\n",
    "accu_score(Wtest_accuracy_lgb4,\"score40_train\")\n",
    "accu_score(Wtrain_accuracy_lgb4,\"score40_train\")\n",
    "\n",
    "accu_score(Mtest_accuracy_xgb4,,\"score40_train\")\n",
    "accu_score(Mtrain_accuracy_xgb4,\"score40_train\")\n",
    "accu_score(Mtest_accuracy_xgb3,,\"score30_train\")\n",
    "accu_score(Mtrain_accuracy_xgb3,\"score30_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "Wfactor1_lgb3.to_pickle(\"./factor_test_data/LightGBM_allfactor2/Wfactor1_lgb3\")\n",
    "Wfactor1_lgb4.to_pickle(\"./factor_test_data/LightGBM_allfactor2/Wfactor1_lgb4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #因子测试1--月频数据\n",
    "Mfactor1_lgb3_obj=factor_analyse(\"test1\",Mfactor1_lgb3)\n",
    "Mfactor1_lgb4_obj=factor_analyse(\"test1\",Mfactor1_lgb4)\n",
    "\n",
    "Mfactor1_xgb3_obj=factor_analyse(\"test1\",Mfactor1_xgb3)\n",
    "Mfactor1_xgb4_obj=factor_analyse(\"test1\",Mfactor1_xgb4)\n",
    "\n",
    "Mfactor1_RF3_obj=factor_analyse(\"test1\",Mfactor1_RF3)\n",
    "Mfactor1_RF4_obj=factor_analyse(\"test1\",Mfactor1_RF4)\n",
    "\n",
    "Mfactor1_GBoost3_obj=factor_analyse(\"test1\",Mfactor1_GBoost3)\n",
    "Mfactor1_GBoost4_obj=factor_analyse(\"test1\",Mfactor1_GBoost4)\n",
    "\n",
    "# #因子测试2--月频数据\n",
    "Msamew_lgb3_pre,Msamew_lgb3_unpre,Munw_lgb3_pre,Munw_lgb3_unpre=factor_stock_choose(Mfactor1_lgb3,100)\n",
    "Msamew_lgb4_pre,Msamew_lgb4_unpre,Munw_lgb4_pre,Munw_lgb4_unpre=factor_stock_choose(Mfactor1_lgb4,100)\n",
    "\n",
    "Msamew_xgb3_pre,Msamew_xgb3_unpre,Munw_xgb3_pre,Munw_xg34_unpre=factor_stock_choose(Mfactor1_xgb3,100)\n",
    "Msamew_xgb4_pre,Msamew_xgb4_unpre,Munw_xgb4_pre,Munw_xgb4_unpre=factor_stock_choose(Mfactor1_xgb4,100)\n",
    "\n",
    "Msamew_GBoost4_pre,Msamew_GBoost4_unpre,Munw_GBoost4_pre,Munw_GBoost4_unpre=factor_stock_choose(Mfactor1_GBoost4,100)\n",
    "Msamew_GBoost3_pre,Msamew_GBoost3_unpre,Munw_GBoost3_pre,Munw_GBoost3_unpre=factor_stock_choose(Mfactor1_GBoost3,100)\n",
    "\n",
    "Msamew_RF3_pre,Msamew_RF3_unpre,Munw_GRF3_pre,Munw_RF3_unpre=factor_stock_choose(Mfactor1_RF3,100)\n",
    "Msamew_RF4_pre,Msamew_RF4_unpre,Munw_RF4_pre,Munw_RF4_unpre=factor_stock_choose(Mfactor1_RF4,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #因子测试1--周频数据\n",
    "Wfactor1_lgb3_obj=factor_analyse(\"test1\",Wfactor1_lgb3)\n",
    "Wfactor1_lgb4_obj=factor_analyse(\"test1\",Wfactor1_lgb4)\n",
    "\n",
    "Wfactor1_xgb3_obj=factor_analyse(\"test1\",Wfactor1_xgb3)\n",
    "Wfactor1_xgb4_obj=factor_analyse(\"test1\",Wfactor1_xgb4)\n",
    "\n",
    "Wfactor1_RF3_obj=factor_analyse(\"test1\",Wfactor1_RF3)\n",
    "Wfactor1_RF4_obj=factor_analyse(\"test1\",Wfactor1_RF4)\n",
    "\n",
    "Wfactor1_GBoost3_obj=factor_analyse(\"test1\",Wfactor1_GBoost3)\n",
    "Wfactor1_GBoost4_obj=factor_analyse(\"test1\",Wfactor1_GBoost4)\n",
    "\n",
    "# #因子测试2--周频数据\n",
    "Wsamew_lgb3_pre,Wsamew_lgb3_unpre,Wunw_lgb3_pre,Wunw_lgb3_unpre=factor_stock_choose(Wfactor1_lgb3,100)\n",
    "Wsamew_lgb4_pre,Wsamew_lgb4_unpre,Wunw_lgb4_pre,Wunw_lgb4_unpre=factor_stock_choose(Wfactor1_lgb4,100)\n",
    "\n",
    "Wsamew_xgb3_pre,Wsamew_xgb3_unpre,Wunw_xgb3_pre,Wunw_xg34_unpre=factor_stock_choose(Wfactor1_xgb3,100)\n",
    "Wsamew_xgb4_pre,Wsamew_xgb4_unpre,Wunw_xgb4_pre,Wunw_xgb4_unpre=factor_stock_choose(Wfactor1_xgb4,100)\n",
    "\n",
    "Wsamew_GBoost4_pre,Wsamew_GBoost4_unpre,Wunw_GBoost4_pre,Wunw_GBoost4_unpre=factor_stock_choose(Wfactor1_GBoost4,100)\n",
    "Wsamew_GBoost3_pre,Wsamew_GBoost3_unpre,Wunw_GBoost3_pre,Wunw_GBoost3_unpre=factor_stock_choose(Wfactor1_GBoost3,100)\n",
    "\n",
    "Wsamew_RF3_pre,Wsamew_RF3_unpre,Wunw_GRF3_pre,Wunw_RF3_unpre=factor_stock_choose(Wfactor1_RF3,100)\n",
    "Wsamew_RF4_pre,Wsamew_RF4_unpre,Wunw_RF4_pre,Wunw_RF4_unpre=factor_stock_choose(Wfactor1_RF4,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示分析图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show2(Wfactor1_lgb3_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probo_class(data,model,loop,date_list,T,x):\n",
    "    train,test=data_input_class(data,date_list,T,x)  \n",
    "    predict_value=[]\n",
    "    test_accuracy=[]\n",
    "    train_accuracy=[]\n",
    "    start_clock  = time.time()\n",
    "    for m in range(len(date_list)-loop):\n",
    "        X_train, X_test, Y_train, Y_test,Xx_test= splitdata(train,test,m+loop-1,m,m+loop-1,m+loop)\n",
    "        model.fit(X_train,Y_train)\n",
    "        predict=model.predict_proba(X_test)\n",
    "        predict=pd.DataFrame(predict)\n",
    "        score_test=model.score(X_test,Y_test)\n",
    "        score_train=model.score(X_train,Y_train)\n",
    "        predict['stock']=Xx_test[:,-2]\n",
    "        predict['date']=Xx_test[:,-1] \n",
    "        predict_value.append(predict)\n",
    "        test_accuracy.append(score_test)\n",
    "        train_accuracy.append(score_train)\n",
    "    end_clock = time.time()\n",
    "    print('cpu cost time: ', end_clock - start_clock)\n",
    "    factor0_df,factor1_df=changeindex2(predict_value,loop,date_list)\n",
    "    return  factor0_df,factor1_df,test_accuracy,train_accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类模型(GBoost，RF，XGB，LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,  GradientBoostingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "GBoost = GradientBoostingClassifier(n_estimators=3000, learning_rate=0.05,max_depth=5)\n",
    "RF = RandomForestClassifier(max_depth=5)\n",
    "model_xgb = xgb.XGBClassifier(learning_rate=0.05, max_depth=5, )\n",
    "model_lgb = lgb.LGBMClassifier(num_leaves=50,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#标签值--分类\n",
    "def rise_fall_class(trade_date_m_series,T):\n",
    "    zz_df = dao.get_index_component_data('ZZ')\n",
    "    stock_price_df = dao.get_security_info('stock_price_info')[trade_date_m_series]\n",
    "    stock_close_df = stock_price_df.xs('close',level=1)[trade_date_m_series]\n",
    "    trade_status_df = stock_price_df.xs('trade_status', level=1)[trade_date_m_series]\n",
    "    pause_df = trade_status_df.copy()\n",
    "    pause_df[pause_df == 1] = np.nan\n",
    "    pause_df[pause_df==0] = 1\n",
    "\n",
    "    stock_chg_df = stock_close_df.pct_change(axis=1)\n",
    "    stock_return_df = stock_chg_df * pause_df  * zz_df\n",
    "    stock_return_df = stock_return_df.shift(-1, axis=1)\n",
    "\n",
    "    is_rise_df = stock_return_df.copy()\n",
    "    rise_quatile_percent = T\n",
    "    rise_quan30_series = is_rise_df.quantile(rise_quatile_percent)\n",
    "    rise_quan70_series = is_rise_df.quantile(1.0 - rise_quatile_percent)\n",
    "\n",
    "    is_rise_df[is_rise_df>rise_quan70_series] = 999\n",
    "    is_rise_df[is_rise_df<rise_quan30_series] = -999\n",
    "    is_rise_df[is_rise_df.abs() != 999] = np.nan\n",
    "\n",
    "    is_rise_df.replace(to_replace=[-999, 999], value=[-1, 1], inplace=True)\n",
    "    return is_rise_df\n",
    "\n",
    "#划分测试集和训练集\n",
    "def concat_data(data,date_list,is_rise_df):\n",
    "    factor_class_series = data.map(lambda x: x.loc[:,date_list[0]:date_list[-1]])\n",
    "    data_df = pd.DataFrame()\n",
    "    factor_name_list = factor_class_series.index.tolist()\n",
    "    data_dict = {}\n",
    "    for trade_date in tqdm(date_list[:]):\n",
    "        data_section_series = factor_class_series.map(lambda x: x[trade_date] if trade_date in x.columns else None)\n",
    "        data_section_df = pd.DataFrame(data_section_series.to_dict())\n",
    "        data_section_df =data_section_df.reindex(columns=factor_name_list)\n",
    "        data_section_df['rise_fall'] = is_rise_df[trade_date]\n",
    "        data_dict[trade_date] = data_section_df\n",
    "        data_section_df['date'] = trade_date\n",
    "    return data_dict\n",
    "    \n",
    "def data_train_test(data_pct,x):\n",
    "    data_pct['rise_fall']=data_pct['rise_fall'].fillna(x)    #注意fillna填充！！！(x=-1是标志值二分类，分为“-1,1”两类)\n",
    "#     data_pct['rise_fall']=data_pct['rise_fall'].fillna(0)   #x=0是标志值三分类，分为“-1,0，1”两类\n",
    "    data_pct_test=data_pct      #包含0，-1,1的三种分类的全部数据预测集\n",
    "    data_pct_test=data_pct[data_pct['trade_status']==0]        #选择正常股票状态的数据\n",
    "#     data_pct_test=data_pct_test.dropna()    #删除空值\n",
    "    data_pct_train=data_pct[~data_pct['rise_fall'].isin([0])]        #不包含0的训练集\n",
    "    data_pct_train=data_pct_train[data_pct_train['trade_status']==0]       #选择正常股票状态的数据\n",
    "#     data_pct_dropna_train=data_pct_train.dropna()\n",
    "    return data_pct_train,data_pct_test\n",
    "\n",
    "def data_input_class(data,date_list,T,x):\n",
    "    is_rise_df=rise_fall_class(date_list,T)    \n",
    "    data_dict=concat_data(data,date_list,is_rise_df)\n",
    "    data_df = pd.concat([data_dict[frame] for frame in data_dict.keys()])\n",
    "    train1,test1=data_train_test(data_df,x) \n",
    "    return train1,test1\n",
    "\n",
    "# 数据标准化，可以处理空值\n",
    "def standard(X_train,X_test):\n",
    "    X_train_scaled =1.0 * (X_train - X_train.mean()) / X_train.std()  # 数据标准化\n",
    "    X_test_scaled =1.0 * (X_test - X_test.mean()) / X_test.std()  # 数据标准化\n",
    "    return  X_train_scaled,X_test_scaled \n",
    "\n",
    "def countsum(data):\n",
    "    a=data.reset_index()\n",
    "    a.rename(columns=lambda x:x.replace('index','stock'), inplace=True) \n",
    "    resultdata=(a['stock'].groupby(a['date'])).describe()\n",
    "    resultdata['sum']=resultdata['count'].cumsum()\n",
    "    return resultdata,a\n",
    "\n",
    "#两分类划分，划分训练集data，测试集alldata（训练集的类别只有（0,1），测试集包含所有类别（0,1，-1））\n",
    "def splitdata(data,alldata,i,j,x,y):\n",
    "    resultdata,a=countsum(data)\n",
    "    resultalldata,b=countsum(alldata)\n",
    "    i=resultdata['sum'][i]\n",
    "    j=resultdata['sum'][j]\n",
    "    x=resultalldata['sum'][x]\n",
    "    y=resultalldata['sum'][y]\n",
    "\n",
    "    newname=fill_alpha_factor_series.index.tolist()    \n",
    "    newname.append('stock')\n",
    "    newname.append('date')\n",
    "\n",
    "    X_train=np.array(a[newname][j:i])\n",
    "    Y_train=np.array(a['rise_fall'][j:i])\n",
    "    #第x个月，测试集\n",
    "    X_test=np.array(b[newname][x:y])\n",
    "    Y_test=np.array(b['rise_fall'][x:y])\n",
    "    X_train_scaled,X_test_scaled=X_train[:,:-3],X_test[:,:-3]\n",
    "\n",
    "    return X_train_scaled,X_test_scaled,Y_train,Y_test,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#按照行业均值进行填充\n",
    "def fillna_ind_mean(data,date_list):\n",
    "    industry_class_df=dao.get_stock_industry_data('CS')               #股票行业信息----周频信息\n",
    "    industry_class_m_df=industry_class_df.loc[:,date_list]    #股票行业信息----月频信息\n",
    "    #按照行进行填充，下一个值\n",
    "    industry_class_m_df=industry_class_m_df.fillna(method='bfill',axis=1)\n",
    "    industry_class_m_df=industry_class_m_df.fillna('未知')  \n",
    "\n",
    "    for i in range(1,len(date_list)):\n",
    "        resl_series = pd.Series() \n",
    "        industry_series=industry_class_m_df.iloc[:,i]\n",
    "        group_data = industry_series.index.groupby(industry_series.values) \n",
    "        industry_list = list(group_data.keys())   \n",
    "        data_series=data.iloc[:,i]\n",
    "        for industry_name in industry_list:      \n",
    "            industry_temp = data_series.loc[group_data[industry_name]]\n",
    "            industry_temp = industry_temp.fillna(industry_temp.mean())         \n",
    "            resl_series = resl_series.append(industry_temp)\n",
    "        stock_list = list(set(data_series.index) - set(industry_series.dropna().index))\n",
    "        resl_series = resl_series.append(data_series.loc[stock_list])\n",
    "        data.iloc[:,i]=resl_series\n",
    "    return data\n",
    "\n",
    "#只做均值填充\n",
    "def data_fillna_mean(df,date_list):\n",
    "    df=fillna_ind_mean(df,date_list)\n",
    "    return df\n",
    "\n",
    "#空值填充，行业均值填充\n",
    "def nonefill(data,date_list):\n",
    "    tempdata=data\n",
    "    for i in tempdata:\n",
    "        i=data_fillna_mean(i,date_list)\n",
    "    return tempdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测准确率分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预测准确率分析\n",
    "def accu_score(score,name):\n",
    "    plt.axhline(0.5,color='red')\n",
    "    plt.plot(score)\n",
    "    plt.text(score[1],score[1],name,fontdict={'size':'16','color':'black'})\n",
    "    plt.title(\"Accuracy on TestData\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子数据合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def change(data,n,m,M,date_list):\n",
    "    date=date_list[M:]\n",
    "    factor_df=pd.DataFrame(columns=date)\n",
    "    factor_df['stock']=list(fill_alpha_factor_series[100].index)\n",
    "    for i,t in itertools.zip_longest(data,date):\n",
    "        temp=factor_df[['stock']]\n",
    "        temp[t]=np.nan\n",
    "        u=i.iloc[:,[n,m]]\n",
    "        u.columns=[t,'stock']\n",
    "        factor_Crash=pd.concat([u,temp],join='inner',ignore_index=True)\n",
    "        factor_Crash.sort_values(t,inplace=True)\n",
    "        factor_Crash.drop_duplicates(['stock'],inplace=True)\n",
    "        factor_Crash.sort_values('stock',inplace=True)\n",
    "        factor_Crash.reset_index(inplace=True)\n",
    "        factor_df[t]= factor_Crash[t]\n",
    "    factorF_df=factor_df.set_index(['stock'])\n",
    "    return factorF_df\n",
    "\n",
    "def changeindex2(data,M,date_list):\n",
    "    factor0_df=change(data,0,2,M,date_list)\n",
    "    factor1_df=change(data,1,2,M,date_list)\n",
    "    return  factor0_df,factor1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子显著度T检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util.factortool as ftool\n",
    "def factor_test_T(factor_list,factor_name): \n",
    "    risk_test=pd.DataFrame()\n",
    "    for i ,n in itertools.zip_longest(factor_list,factor_name):\n",
    "        risk_test[n]=ftool.factor_risk_test_tvalue(i)\n",
    "    return  risk_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子测试1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphafactors.factorprepro_class as fp\n",
    "import alphafactors.factoranalyse as fa\n",
    "\n",
    "#因子处理(分成两种方向)\n",
    "def factor_analyse(name,factor):  # 0-positive , 1-negetive\n",
    "    factor_prepro_obj = fp.FactorPrePro(factor_name=name, factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    factor_test_obj = fa.FactorAnalyse(factor_name=name, factor_data_df=df, factor_dr=0)   # 0-positive , 1-negetive\n",
    "    factor_test_obj.run_analyse_new(start_date=dt.datetime(2009,1,23), universe='ZZ')\n",
    "    return factor_test_obj\n",
    "\n",
    "#因子测试画图显示\n",
    "def show1(factor_test_obj):\n",
    "    factor_test_obj.net_value_df.iloc[:,-3:].plot(figsize=(20,10))\n",
    "def show2(factor_test_obj):\n",
    "    factor_test_obj.factor_perform_df\n",
    "    return  factor_test_obj.factor_perform_df\n",
    "def show3(factor_test_obj):\n",
    "    factor_test_obj.factor_para_df\n",
    "    return  factor_test_obj.factor_para_df\n",
    "def show4(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df\n",
    "    return     factor_test_obj.port_perform_df\n",
    "def show5(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')\n",
    "    return factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')   \n",
    "def show6(factor_test_obj):\n",
    "    factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')\n",
    "    return  factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子测试2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util.evalstat as evl\n",
    "                                     \n",
    "def factor_test_pre(factor):         #因子中性化预处理\n",
    "    factor_prepro_obj = fp.FactorPrePro(factor_name='factor_test', factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    return df\n",
    "\n",
    "def factor_test(stock_weighted_series):\n",
    "    perform_obj=evl.PortPerform(port_series=stock_weighted_series,ret_type='open',fee=0.0035)\n",
    "    perform_obj.run()\n",
    "    return perform_obj\n",
    "\n",
    "def show01(perform_obj):\n",
    "    perform_obj.net_value_plot()        \n",
    "def show02(perform_obj):\n",
    "    perform_obj.get_strategy_perform() \n",
    "    return perform_obj.get_strategy_perform()      \n",
    "def show03(perform_obj):\n",
    "    perform_obj.get_avg_turnover()  \n",
    "    return perform_obj.get_avg_turnover()      \n",
    "def show04(perform_obj):\n",
    "    perform_obj.get_annual_perform()  \n",
    "    return  perform_obj.get_annual_perform()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 投资组合构建（2种：一种等权，一种不等权）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_choice(data,num):                 #直接挑选概率值前100支股票，等权\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "        stock_series.loc[i]=pd.Series(index=[data[i].sort_values(ascending=False).head(num).index],data=1/num)\n",
    "    stock_choice_obj=factor_test(stock_series)\n",
    "    \n",
    "    return stock_choice_obj\n",
    "\n",
    "def stock_bench_ind(data,num):   #行业中性，基准权重后挑选100支股票\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "       set_date=i\n",
    "       stock_series[i]=get_industry_stock(data[i], set_date, stock_num=num)\n",
    "    stock_choice_obj =factor_test(stock_series)\n",
    "\n",
    "    return stock_choice_obj\n",
    "\n",
    "def factor_stock_choose(factor,num):\n",
    "    factor_obj=factor_test_pre(factor)   #做因子预处理\n",
    "    #等权选num支\n",
    "    samew_pre=stock_choice(factor_obj,num)\n",
    "    samew_unpre=stock_choice(factor,num)   #不做因子预处理，等权直接选100支\n",
    "    #不等权选num支\n",
    "    unw_pre=stock_bench_ind(factor_obj,num)\n",
    "    unw_unpre=stock_bench_ind(factor,num)\n",
    "    return samew_pre,samew_unpre,unw_pre,unw_unpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基准行业权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_industry_df = dao.get_security_info('stock_industry_CS')\n",
    "stock_industry_list = dso.get_industry_classify('CS')\n",
    "stock_pool_df = dao.get_index_component_data('DEF')\n",
    "\n",
    "def get_bench_ind_weight(set_date, bench_code='ZZ500'):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "    # 基准行业权重\n",
    "    bench_component_df = dao.get_index_component_data(bench_code)\n",
    "    bench_series = pd.Series(bench_component_df[set_date].set_index('code')['weight'])\n",
    "    bench_series = bench_series / bench_series.sum()\n",
    "    bench_ind_weight_series = pd.Series(index=stock_industry_list)\n",
    "    for industry_name in stock_industry_list:\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        temp_series = bench_series.copy()\n",
    "        bench_ind_weight_series.loc[industry_name] = temp_series.reindex(ind_stock_list).sum()\n",
    "    bench_ind_weight_series.fillna(0, inplace=True)\n",
    "    return bench_ind_weight_series\n",
    "\n",
    "\n",
    "def get_industry_stock(stock_factor_series, set_date, stock_num=100):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    stock_series = stock_pool_df[set_date]\n",
    "    stock_list = industry_series.index.intersection(stock_series.dropna().index).tolist()\n",
    "    industry_series = industry_series.loc[stock_list]\n",
    "\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "\n",
    "    # 基准行业权重\n",
    "    bench_ind_weight_series = get_bench_ind_weight(set_date=set_date)\n",
    "    bench_ind_num_series = round(bench_ind_weight_series * stock_num).astype(int)\n",
    "\n",
    "    port_series = pd.Series()\n",
    "    # 得到行业中性组合\n",
    "    for industry_name in stock_industry_list[:]:\n",
    "        if bench_ind_weight_series[industry_name] <= 0.0:\n",
    "            continue\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        ind_stock_series = pd.Series(stock_factor_series.loc[ind_stock_list]).reindex(ind_stock_list).sort_values(\n",
    "            ascending=False)\n",
    "\n",
    "        ind_stock_num = bench_ind_num_series[industry_name]\n",
    "        if ind_stock_num < 1:\n",
    "            ind_stock_num += 1\n",
    "\n",
    "        if ind_stock_series.shape[0] >= ind_stock_num:\n",
    "            xx = ind_stock_series.head(ind_stock_num)\n",
    "            temp_series = xx / xx.sum() * bench_ind_weight_series[industry_name]\n",
    "        else:\n",
    "            temp_series = ind_stock_series / ind_stock_series.sum() * bench_ind_weight_series[industry_name]\n",
    "\n",
    "            temp_series = pd.Series(index=ind_stock_series.index[:ind_stock_num], data=1.0 / ind_stock_num) * \\\n",
    "                          bench_ind_weight_series[industry_name]\n",
    "        port_series = port_series.append(temp_series)\n",
    "    return port_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
