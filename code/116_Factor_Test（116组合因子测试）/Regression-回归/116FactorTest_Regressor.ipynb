{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共选取六大类因子中的106个特征值+10个风险因子，进行回归预测\n",
    "回归目标值为：股票涨跌幅\n",
    "滚动预测：前12期预测下一期（月频数据）\n",
    "        前48期预测下一期（周频数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import daolib.dao as dao\n",
    "import daolib.dso as dso\n",
    "import util.sectool as sectool\n",
    "import util.operatetool as optool\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#直接从文件夹读取分类构造好的数据\n",
    "week_alpha_factor_series=pickle.load(open(\"./factor_test_data/LightGBM_allfactor/week_alpha_factor_series\",\"rb+\"))  #周频数据\n",
    "month_alpha_factor_series=pickle.load(open(\"./factor_test_data/LightGBM_allfactor/month_alpha_factor_series\",\"rb+\")) #月频数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wscore_lasso,Wscore_ENet,Wscore_KRR ,Wscore_GBoost,Wscore_xgb,Wscore_lgb =  rmse_siglemodel(week_alpha_factor_series,12,week_list) #周频数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE画图分析（看rmse平均值）\n",
    "rmse_list=[lasso_rmse,ENet_rmse,xgb_rmse,lgb_rmse,GBoost_rmse]\n",
    "label_list=['lasso_rmse','ENet_rmse','xgb_rmse','lgb_rmse','GBoost_rmse']\n",
    "rmse_show(rmse_list,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最终模型的预测结果\n",
    "lasso_rmse,lasso_predict_value=rmsle(lasso,month_alpha_factor_series,12,month_list)\n",
    "ENet_rmse,ENet_predict_value=rmsle(ENet,month_alpha_factor_series,12,month_list)\n",
    "lgb_rmse,lgb_predict_value=rmsle(model_lgb,month_alpha_factor_series,12,month_list)\n",
    "xgb_rmse,xgb_predict_value=rmsle(model_xgb,month_alpha_factor_series,12,month_list)\n",
    "GBoost_rmse,GBoost_predict_value=rmsle(GBoost,month_alpha_factor_series,12,month_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单平均模型融合，（选择最小rmse的三个模型），计算融合模型的rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (ENet,model_lgb,lasso,model_lgb))\n",
    "averaged_score1 = rmsle_cv(averaged_models,month_alpha_factor_series,12,month_list)\n",
    "averaged_score2,averaged_predict_value=rmsle(averaged_models,month_alpha_factor_series,12,month_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-model模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet,model_lgb, model_xgb),meta_model = lasso)\n",
    "stacked_averaged_score1 = rmsle_cv(stacked_averaged_models,month_alpha_factor_series,12,month_list)\n",
    "stacked_averaged_score2,stacked_averaged_predict_value=rmsle(stacked_averaged_models,month_alpha_factor_series,12,month_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#最终的数据融合（分配不同权重）\n",
    "# ensemble1 = GBoost_predict_value*0.7+ xgb_predict_value*0.15 +lgb_predict_value*0.15\n",
    "# ensemble2 = GBoost_predict_value*0.8+ xgb_predict_value*0.1 +lgb_predict_value*0.1\n",
    "ensemble3 = GBoost_predict_value*0.6+ xgb_predict_value*0.2 +lgb_predict_value*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "stacked_averaged_predict_value.to_pickle(\"./factor_test_data/LightGBM_allfactor2/stacked_averaged_predict_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#因子测试1\n",
    "averaged_predict_value_obj=factor_analyse('test1',averaged_predict_value)\n",
    "#因子测试2\n",
    "average_samew_pre,average_samew_unpre,average_unw_pre,average_unw_unpre=factor_stock_choose(averaged_predict_value,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归模型（lasso，ENet，KRR，GBoost，model_xgb，model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,max_depth=4, max_features='sqrt',)\n",
    "\n",
    "RF=RandomForestRegressor(max_depth=5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(learning_rate=0.05, max_depth=5, )\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=50,learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个模型分数评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#模型分数评估（采用交叉验证三折评估，计算RMSE）\n",
    "n_folds=3\n",
    "def rmsle_cv(model,data,M,date_list):\n",
    "    RMSE=[]\n",
    "    train,test=data_input_reg(data,date_list) \n",
    "    for m in range(len(date_list)-M-4):\n",
    "        X_train, X_test, Y_train, Y_test,Xx_test= splitdata(data,train,test,m+M-1,m,m+M-1,m+M)\n",
    "        kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "        rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "        RMSE.append(rmse)\n",
    "    mean_rmse=np.array(RMSE).mean()\n",
    "    return mean_rmse\n",
    "\n",
    "def rmse_siglemodel(data,loop,date_list):    #单个回归模型评估（三折评估计算rmse）\n",
    "    regscore_lasso= rmsle_cv(lasso,data,loop,date_list)\n",
    "    regscore_ENet = rmsle_cv(ENet,data,loop,date_list)\n",
    "    regscore_KRR = rmsle_cv(KRR,data,loop,date_list)\n",
    "    regscore_GBoost = rmsle_cv(GBoost,data,loop,date_list)\n",
    "    regscore_xgb = rmsle_cv(model_xgb,data,loop,date_list)\n",
    "    regscore_lgb = rmsle_cv(model_lgb,data,loop,date_list)\n",
    "    return   regscore_lasso,regscore_ENet,regscore_KRR ,regscore_GBoost,regscore_xgb,regscore_lgb   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最终预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(model,data,loop,date_list):\n",
    "    RMSE=[]\n",
    "    predict_value=[]\n",
    "    train,test=data_input_reg(data,date_list) \n",
    "    for m in range(len(date_list)-loop-4):\n",
    "        X_train, X_test, Y_train, Y_test,Xx_test= splitdata(data,train,test,m+loop-1,m,m+loop-1,m+loop)\n",
    "        model.fit(X_train, Y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        y_pred =model.predict(X_test)\n",
    "        y_pred=pd.DataFrame(y_pred)\n",
    "        y_pred['stock']=Xx_test[:,-2]\n",
    "        y_pred['date']=Xx_test[:,-1] \n",
    "        rmse=np.sqrt(mean_squared_error(Y_train, train_pred))\n",
    "        RMSE.append(rmse)\n",
    "        predict_value.append(y_pred)\n",
    "    factor=changeindex1(predict_value,loop,date_list)\n",
    "    return RMSE,factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确率分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE画图分析（看平均值）\n",
    "def rmse_show(rmse_list,label_list):\n",
    "    for i in rmse_list:\n",
    "        plt.plot(i,\"x-\",label=label_list[rmse_list.index(i)])\n",
    "    plt.legend() \n",
    "    for i in rmse_list:\n",
    "        print(label_list[rmse_list.index(i)],\"平均RMSE为:\",np.array(i).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单平均模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta-model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#标签值-回归\n",
    "def rise_fall_reg(trade_date_m_series):\n",
    "    zz_df = dao.get_index_component_data('ZZ')\n",
    "    stock_price_df = dao.get_security_info('stock_price_info')[trade_date_m_series]\n",
    "    stock_close_df = stock_price_df.xs('close',level=1)[trade_date_m_series]\n",
    "    trade_status_df = stock_price_df.xs('trade_status', level=1)[trade_date_m_series]\n",
    "    pause_df = trade_status_df.copy()\n",
    "    pause_df[pause_df == 1] = np.nan\n",
    "    pause_df[pause_df==0] = 1\n",
    "\n",
    "    stock_chg_df = stock_close_df.pct_change(axis=1)\n",
    "    stock_return_df = stock_chg_df * pause_df  * zz_df\n",
    "    stock_return_df = stock_return_df.shift(-1, axis=1)\n",
    "    return stock_return_df\n",
    "\n",
    "#划分测试集和训练集\n",
    "def concat_data(data,date_list,is_rise_df):\n",
    "    factor_class_series = data.map(lambda x: x.loc[:,date_list[0]:date_list[-1]])\n",
    "    data_df = pd.DataFrame()\n",
    "    factor_name_list = factor_class_series.index.tolist()\n",
    "    data_dict = {}\n",
    "    for trade_date in tqdm(date_list[:]):\n",
    "        data_section_series = factor_class_series.map(lambda x: x[trade_date] if trade_date in x.columns else None)\n",
    "        data_section_df = pd.DataFrame(data_section_series.to_dict())\n",
    "        data_section_df =data_section_df.reindex(columns=factor_name_list)\n",
    "        data_section_df['rise_fall'] = is_rise_df[trade_date]\n",
    "        data_dict[trade_date] = data_section_df\n",
    "        data_section_df['date'] = trade_date\n",
    "    return data_dict\n",
    "    \n",
    "def data_train_test(data_pct):\n",
    "    data_pct_test=data_pct      #包含0，-1,1的三种分类的全部数据预测集\n",
    "    data_pct_test=data_pct[data_pct['trade_status']==0]        #选择正常股票状态的数据\n",
    "    data_pct_test=data_pct_test.dropna()    #删除空值（回归空值太多）\n",
    "    data_pct_train=data_pct     #不包含0的训练集\n",
    "    data_pct_train=data_pct_train[data_pct_train['trade_status']==0]       #选择正常股票状态的数据\n",
    "    data_pct_train=data_pct_train.dropna()\n",
    "    return data_pct_train,data_pct_test\n",
    "\n",
    "def data_input_reg(data,date_list):\n",
    "    is_rise_df=rise_fall_reg(date_list)    \n",
    "    data_dict=concat_data(data,date_list,is_rise_df)\n",
    "    data_df = pd.concat([data_dict[frame] for frame in data_dict.keys()])\n",
    "    train1,test1=data_train_test(data_df) \n",
    "    return train1,test1\n",
    "\n",
    "# 数据标准化，可以处理空值\n",
    "def standard(X_train,X_test):\n",
    "    X_train_scaled =1.0 * (X_train - X_train.mean()) / X_train.std()  # 数据标准化\n",
    "    X_test_scaled =1.0 * (X_test - X_test.mean()) / X_test.std()  # 数据标准化\n",
    "    return  X_train_scaled,X_test_scaled \n",
    "\n",
    "def countsum(data):\n",
    "    a=data.reset_index()\n",
    "    a.rename(columns=lambda x:x.replace('index','stock'), inplace=True) \n",
    "    resultdata=(a['stock'].groupby(a['date'])).describe()\n",
    "    resultdata['sum']=resultdata['count'].cumsum()\n",
    "    return resultdata,a\n",
    "\n",
    "#两分类划分，划分训练集data，测试集alldata（训练集的类别只有（0,1），测试集包含所有类别（0,1，-1））\n",
    "def splitdata(data,train,test,i,j,x,y):\n",
    "    resultdata,a=countsum(train)\n",
    "    resultalldata,b=countsum(test)\n",
    "    i=resultdata['sum'][i]\n",
    "    j=resultdata['sum'][j]\n",
    "    x=resultalldata['sum'][x]\n",
    "    y=resultalldata['sum'][y]\n",
    "\n",
    "    newname=data.index.tolist()    \n",
    "    newname.append('stock')\n",
    "    newname.append('date')\n",
    "\n",
    "    X_train=np.array(a[newname][j:i])\n",
    "    Y_train=np.array(a['rise_fall'][j:i])\n",
    "    #第x个月，测试集\n",
    "    X_test=np.array(b[newname][x:y])\n",
    "    Y_test=np.array(b['rise_fall'][x:y])\n",
    "    X_train_scaled,X_test_scaled=X_train[:,:-3],X_test[:,:-3]\n",
    "    return X_train_scaled,X_test_scaled,Y_train,Y_test,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子数据合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def change(data,n,m,M,date_list):\n",
    "    date=date_list[M:-4]\n",
    "    factor_df=pd.DataFrame(columns=date)\n",
    "    factor_df['stock']=list(month_alpha_factor_series[100].index)\n",
    "#     factor_df['stock']=data['stock']\n",
    "\n",
    "    for i,t in itertools.zip_longest(data,date):\n",
    "        temp=factor_df[['stock']]\n",
    "        temp[t]=np.nan\n",
    "        u=i.iloc[:,[n,m]]\n",
    "        u.columns=[t,'stock']\n",
    "        factor_Crash=pd.concat([u,temp],join='inner',ignore_index=True)\n",
    "        factor_Crash.sort_values(t,inplace=True)\n",
    "        factor_Crash.drop_duplicates(['stock'],inplace=True)\n",
    "        factor_Crash.sort_values('stock',inplace=True)\n",
    "        factor_Crash.reset_index(inplace=True)\n",
    "        factor_df[t]= factor_Crash[t]\n",
    "    factorF_df=factor_df.set_index(['stock'])\n",
    "    return factorF_df\n",
    "\n",
    "def changeindex1(data,M,date_list):\n",
    "    factor_df=change(data,0,1,M,date_list)\n",
    "    return  factor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子显著度T检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util.factortool as ftool\n",
    "def factor_test_T(factor_list,factor_name): \n",
    "    risk_test=pd.DataFrame()\n",
    "    for i ,n in itertools.zip_longest(factor_list,factor_name):\n",
    "        risk_test[n]=ftool.factor_risk_test_tvalue(i)\n",
    "    return  risk_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子测试1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphafactors.factorprepro_class as fp\n",
    "import alphafactors.factoranalyse as fa\n",
    "\n",
    "#因子处理(分成两种方向)\n",
    "def factor_analyse(name,factor):  # 0-positive , 1-negetive\n",
    "    factor_prepro_obj = fp.FactorPrePro(factor_name=name, factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    factor_test_obj = fa.FactorAnalyse(factor_name=name, factor_data_df=df, factor_dr=0)   # 0-positive , 1-negetive\n",
    "    factor_test_obj.run_analyse_new(start_date=dt.datetime(2009,1,23), universe='ZZ')\n",
    "    return factor_test_obj\n",
    "\n",
    "#因子测试画图显示\n",
    "def show1(factor_test_obj):\n",
    "    factor_test_obj.net_value_df.iloc[:,-3:].plot(figsize=(20,10))\n",
    "def show2(factor_test_obj):\n",
    "    factor_test_obj.factor_perform_df\n",
    "    return  factor_test_obj.factor_perform_df\n",
    "def show3(factor_test_obj):\n",
    "    factor_test_obj.factor_para_df\n",
    "    return  factor_test_obj.factor_para_df\n",
    "def show4(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df\n",
    "    return     factor_test_obj.port_perform_df\n",
    "def show5(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')\n",
    "    return factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')   \n",
    "def show6(factor_test_obj):\n",
    "    factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')\n",
    "    return  factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子测试2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util.evalstat as evl\n",
    "                                     \n",
    "def factor_test_pre(factor):         #因子中性化预处理\n",
    "    factor_prepro_obj = fp.FactorPrePro(factor_name='factor_test', factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    return df\n",
    "\n",
    "def factor_test(stock_weighted_series):\n",
    "    perform_obj=evl.PortPerform(port_series=stock_weighted_series,ret_type='open',fee=0.0035)\n",
    "    perform_obj.run()\n",
    "    return perform_obj\n",
    "\n",
    "def show01(perform_obj):\n",
    "    perform_obj.net_value_plot()        \n",
    "def show02(perform_obj):\n",
    "    perform_obj.get_strategy_perform() \n",
    "    return perform_obj.get_strategy_perform()      \n",
    "def show03(perform_obj):\n",
    "    perform_obj.get_avg_turnover()  \n",
    "    return perform_obj.get_avg_turnover()      \n",
    "def show04(perform_obj):\n",
    "    perform_obj.get_annual_perform()  \n",
    "    return  perform_obj.get_annual_perform()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 投资组合构建（2种：一种等权，一种不等权）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_choice(data,num):                 #直接挑选概率值前100支股票，等权\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "        stock_series.loc[i]=pd.Series(index=[data[i].sort_values(ascending=False).head(num).index],data=1/num)\n",
    "    stock_choice_obj=factor_test(stock_series)\n",
    "    return stock_choice_obj\n",
    "\n",
    "def stock_bench_ind(data,num):   #行业中性，基准权重后挑选100支股票\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "       set_date=i\n",
    "       stock_series[i]=get_industry_stock(data[i], set_date, stock_num=num)\n",
    "    stock_choice_obj =factor_test(stock_series)\n",
    "    return stock_choice_obj\n",
    "\n",
    "def factor_stock_choose(factor,num):\n",
    "    factor_obj=factor_test_pre(factor)   #做因子预处理\n",
    "    #等权选num支\n",
    "    samew_pre=stock_choice(factor_obj,num)\n",
    "    samew_unpre=stock_choice(factor,num)   #不做因子预处理，等权直接选100支\n",
    "    #不等权选num支\n",
    "    unw_pre=stock_bench_ind(factor_obj,num)\n",
    "    unw_unpre=stock_bench_ind(factor,num)\n",
    "    return  samew_pre,samew_unpre,unw_pre,unw_unpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基准行业权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_industry_df = dao.get_security_info('stock_industry_CS')\n",
    "stock_industry_list = dso.get_industry_classify('CS')\n",
    "stock_pool_df = dao.get_index_component_data('DEF')\n",
    "\n",
    "def get_bench_ind_weight(set_date, bench_code='ZZ500'):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "    # 基准行业权重\n",
    "    bench_component_df = dao.get_index_component_data(bench_code)\n",
    "    bench_series = pd.Series(bench_component_df[set_date].set_index('code')['weight'])\n",
    "    bench_series = bench_series / bench_series.sum()\n",
    "    bench_ind_weight_series = pd.Series(index=stock_industry_list)\n",
    "    for industry_name in stock_industry_list:\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        temp_series = bench_series.copy()\n",
    "        bench_ind_weight_series.loc[industry_name] = temp_series.reindex(ind_stock_list).sum()\n",
    "    bench_ind_weight_series.fillna(0, inplace=True)\n",
    "    return bench_ind_weight_series\n",
    "\n",
    "def get_industry_stock(stock_factor_series, set_date, stock_num=100):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    stock_series = stock_pool_df[set_date]\n",
    "    stock_list = industry_series.index.intersection(stock_series.dropna().index).tolist()\n",
    "    industry_series = industry_series.loc[stock_list]\n",
    "\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "    # 基准行业权重\n",
    "    bench_ind_weight_series = get_bench_ind_weight(set_date=set_date)\n",
    "    bench_ind_num_series = round(bench_ind_weight_series * stock_num).astype(int)\n",
    "    port_series = pd.Series()\n",
    "    # 得到行业中性组合\n",
    "    for industry_name in stock_industry_list[:]:\n",
    "        if bench_ind_weight_series[industry_name] <= 0.0:\n",
    "            continue\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        ind_stock_series = pd.Series(stock_factor_series.loc[ind_stock_list]).reindex(ind_stock_list).sort_values(\n",
    "            ascending=False)\n",
    "\n",
    "        ind_stock_num = bench_ind_num_series[industry_name]\n",
    "        if ind_stock_num < 1:\n",
    "            ind_stock_num += 1\n",
    "\n",
    "        if ind_stock_series.shape[0] >= ind_stock_num:\n",
    "            xx = ind_stock_series.head(ind_stock_num)\n",
    "            temp_series = xx / xx.sum() * bench_ind_weight_series[industry_name]\n",
    "        else:\n",
    "            temp_series = ind_stock_series / ind_stock_series.sum() * bench_ind_weight_series[industry_name]\n",
    "\n",
    "            temp_series = pd.Series(index=ind_stock_series.index[:ind_stock_num], data=1.0 / ind_stock_num) * \\\n",
    "                          bench_ind_weight_series[industry_name]\n",
    "        port_series = port_series.append(temp_series)\n",
    "    return port_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
