{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "import daolib.dao as dao\n",
    "import daolib.dso as dso\n",
    "import util.sectool as sectool\n",
    "import util.operatetool as optool\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "简单dnn网络构建测试\n",
    "\n",
    "数据：['mom','emotion', 'pricevol', 'minute', 'finance', 'valuation', 'alpha191','growth']  八大类因子组合测试（共计158个因子+1个标签值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha191=readdir('D:\\Data\\\\factor_alpha\\\\alpha191' )\n",
    "finance=readdir('D:\\Data\\\\factor_alpha\\\\finance' )\n",
    "growth=readdir('D:\\Data\\\\factor_alpha\\\\growth' )\n",
    "minute=readdir('D:\\Data\\\\factor_alpha\\\\minute' )\n",
    "pricevol=readdir('D:\\Data\\\\factor_alpha\\\\pricevol' )\n",
    "valuation=readdir('D:\\Data\\\\factor_alpha\\\\valuation' )\n",
    "emotion=readdir('D:\\Data\\\\factor_alpha\\\\emotion' )\n",
    "mom=readdir('D:\\Data\\\\factor_alpha\\\\mom' )\n",
    "\n",
    "stock_price_df = dao.get_security_info('stock_price_info')\n",
    "all_stock_list = stock_price_df.index.get_level_values(0).drop_duplicates().tolist()\n",
    "\n",
    "#股票上市状态(只选择为0的值，不为0的值为异常值)\n",
    "price_df=dao.get_security_info('stock_price_info')\n",
    "trade_status_df=price_df.xs('trade_status',level=1)\n",
    "\n",
    "start_date = dt.datetime(2007, 1, 1)\n",
    "end_date = dt.datetime(2018,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor_name_list = ['mom','emotion', 'pricevol', 'minute', 'finance', 'valuation', 'alpha191','growth']  \n",
    "\n",
    "#周频数据\n",
    "trade_date_w_series = pd.Series( dso.get_trade_date(start_date=start_date, end_date=end_date, period='w') )\n",
    "week_list = [date for date in trade_date_w_series if dt.datetime(2009,10,20)<date and date < dt.datetime(2018,11,1) ]\n",
    "week_data = read_factor_data(factors_name_list=factor_name_list, trade_date_20d_series=trade_date_w_series)\n",
    "week_data['trade_status'] = trade_status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(week_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#按照涨跌幅30%划分测试\n",
    "factor0_df,factor1_df,test_accuracy,train_accuracy=predict_probo_class(week_data,48,week_list,0.3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor1_df_obj=factor_analyse(\"test1\",factor1_df)\n",
    "factor1_pre,factor1_unpre,factor1_pre,factor1_unpre=factor_stock_choose(factor1_df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show2(factor1_df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show01(factor1_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probo_class(data,loop,date_list,T,x):\n",
    "    train,test=data_input_class(data,date_list,T,x)  \n",
    "    predict_value=[]\n",
    "    test_accuracy=[]\n",
    "    train_accuracy=[]\n",
    "    start_clock  = time.time()\n",
    "    for m in range(len(date_list)-loop):\n",
    "        x_train, x_test, y_train, y_test,Xx_test= splitdata(train,test,m+loop-1,m,m+loop-1,m+loop)\n",
    "        y_train=y_train.reshape([len(y_train),1])\n",
    "        y_test=y_test.reshape([len(y_test),1])\n",
    "#         x_train= Imputer().fit_transform(x_train)         #填补缺失值 并且进行归一化\n",
    "#         ss.fit(x_train)\n",
    "#         x_train = ss.transform(x_train)\n",
    "        predict = model_create(x_train,y_train,x_test,y_test)\n",
    "        predict=pd.DataFrame(predict)\n",
    "        predict['stock']=Xx_test[:,-2]\n",
    "        predict['date']=Xx_test[:,-1] \n",
    "        predict_value.append(predict)\n",
    "    \n",
    "    factor0_df,factor1_df=changeindex1(predict_value,loop,date_list)  #??\n",
    "    return  factor0_df,factor1_df,test_accuracy,train_accuracy     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络模型搭建 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_create(x_train,y_train,x_test,y_test):\n",
    "    #定义输入和输出\n",
    "    x = tf.placeholder(tf.float32,shape=(None,2),name=\"x-input\")\n",
    "    y_ = tf.placeholder(tf.float32,shape=(None,1),name=\"y-input\")\n",
    "\n",
    "    #  ///////////////////隐藏层//////////////////////\n",
    "    w1 = tf.Variable(tf.truncated_normal([len(x_train), 30], stddev=0.1,seed=1))\n",
    "    b1 = tf.Variable(tf.zeros([30]))\n",
    "    L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "    w2 = tf.Variable(tf.truncated_normal([30, 20], stddev=0.1,seed=1))\n",
    "    b2 = tf.Variable(tf.zeros([20]))\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal([20, 20], stddev=0.1,seed=1))\n",
    "    b3 = tf.Variable(tf.zeros([20]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2, w3) + b3)\n",
    "    # # ///////////////////隐藏层//////////////////////\n",
    "\n",
    "    # 输出层\n",
    "    w4 = tf.Variable(tf.truncated_normal([20, 1], stddev=0.1,seed=1))\n",
    "    b4 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    y= tf.nn.sigmoid(tf.matmul(L3, w4)+b4)\n",
    "    #基于min和max对张量t进行截断操作，为了应对梯度爆发或者梯度消失的情况\n",
    "    cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y,1e-10,1.0))+(1-y_) * tf.log(tf.clip_by_value(1-y,1e-10,1.0)))\n",
    "    # 使用Adadelta算法作为优化函数，来保证预测值与实际值之间交叉熵最小\n",
    "    train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #初始化变量  tf.initialize_all_variables()\n",
    "            init = tf.initialize_all_variables()\n",
    "            sess.run(init)\n",
    "            #设置神经网络的迭代次数\n",
    "            steps = 500\n",
    "            for i in range(steps):\n",
    "            #通过选取样本训练神经网络并更新参数\n",
    "               for (input_x,input_y) in zip(x_train,y_train):\n",
    "                   input_x = np.reshape(input_x,(1,2))\n",
    "                   input_y = np.reshape(input_y,(1,1))\n",
    "                   sess.run(train_step,feed_dict={x:input_x,y_:input_y})\n",
    "            #每迭代1000次输出一次日志信息\n",
    "               if i % 100 == 0:\n",
    "                # 计算所有数据的交叉熵\n",
    "                total_cross_entropy = sess.run(cross_entropy,feed_dict={x:x_train,y_:y_train})\n",
    "                # 输出交叉熵之和\n",
    "                print(\"After %d training step(s),cross entropy on all data is %g\"%(i,total_cross_entropy))\n",
    "        #预测输入X的类别\n",
    "        pred_Y = sess.run(y,feed_dict={x:x_test})\n",
    "#         print(pred_Y)\n",
    "        return pred_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def rise_fall_reg(trade_date_m_series):\n",
    "    zz_df = dao.get_index_component_data('ZZ')\n",
    "    stock_price_df = dao.get_security_info('stock_price_info')[trade_date_m_series]\n",
    "    stock_close_df = stock_price_df.xs('close',level=1)[trade_date_m_series]\n",
    "    trade_status_df = stock_price_df.xs('trade_status', level=1)[trade_date_m_series]\n",
    "    pause_df = trade_status_df.copy()\n",
    "    pause_df[pause_df == 1] = np.nan\n",
    "    pause_df[pause_df==0] = 1\n",
    "\n",
    "    stock_chg_df = stock_close_df.pct_change(axis=1)\n",
    "    stock_return_df = stock_chg_df * pause_df  * zz_df\n",
    "    stock_return_df = stock_return_df.shift(-1, axis=1)\n",
    "    return stock_return_df\n",
    "\n",
    "#划分测试集和训练集\n",
    "def concat_data(data,date_list,is_rise_df):\n",
    "    factor_class_series = data.map(lambda x: x.loc[:,date_list[0]:date_list[-1]])\n",
    "    data_df = pd.DataFrame()\n",
    "    factor_name_list = factor_class_series.index.tolist()\n",
    "    data_dict = {}\n",
    "    for trade_date in tqdm(date_list[:]):\n",
    "        data_section_series = factor_class_series.map(lambda x: x[trade_date] if trade_date in x.columns else None)\n",
    "        data_section_df = pd.DataFrame(data_section_series.to_dict())\n",
    "        data_section_df =data_section_df.reindex(columns=factor_name_list)\n",
    "        data_section_df['rise_fall'] = is_rise_df[trade_date]\n",
    "        data_dict[trade_date] = data_section_df\n",
    "        data_section_df['date'] = trade_date\n",
    "    return data_dict\n",
    "    \n",
    "def data_train_test(data_pct):\n",
    "    data_pct_test=data_pct      #包含0，-1,1的三种分类的全部数据预测集\n",
    "    data_pct_test=data_pct[data_pct['trade_status']==0]        #选择正常股票状态的数据\n",
    "    data_pct_test=data_pct_test.dropna()    #删除空值（回归空值太多）\n",
    "    data_pct_train=data_pct     #不包含0的训练集\n",
    "    data_pct_train=data_pct_train[data_pct_train['trade_status']==0]       #选择正常股票状态的数据\n",
    "    data_pct_train=data_pct_train.dropna()\n",
    "    return data_pct_train,data_pct_test\n",
    "\n",
    "def data_input_class(data,date_list):\n",
    "    is_rise_df=rise_fall_reg(date_list)    \n",
    "    data_dict=concat_data(data,date_list,is_rise_df)\n",
    "    data_df = pd.concat([data_dict[frame] for frame in data_dict.keys()])\n",
    "    train1,test1=data_train_test(data_df) \n",
    "    return train1,test1\n",
    "\n",
    "# 数据标准化，可以处理空值\n",
    "def standard(X_train,X_test):\n",
    "    X_train_scaled =1.0 * (X_train - X_train.mean()) / X_train.std()  # 数据标准化\n",
    "    X_test_scaled =1.0 * (X_test - X_test.mean()) / X_test.std()  # 数据标准化\n",
    "    return  X_train_scaled,X_test_scaled \n",
    "\n",
    "def countsum(data):\n",
    "    a=data.reset_index()\n",
    "    a.rename(columns=lambda x:x.replace('index','stock'), inplace=True) \n",
    "    resultdata=(a['stock'].groupby(a['date'])).describe()\n",
    "    resultdata['sum']=resultdata['count'].cumsum()\n",
    "    return resultdata,a\n",
    "\n",
    "#两分类划分，划分训练集data，测试集alldata（训练集的类别只有（0,1），测试集包含所有类别（0,1，-1））\n",
    "def splitdata(data,train,test,i,j,x,y):\n",
    "    resultdata,a=countsum(train)\n",
    "    resultalldata,b=countsum(test)\n",
    "    i=resultdata['sum'][i]\n",
    "    j=resultdata['sum'][j]\n",
    "    x=resultalldata['sum'][x]\n",
    "    y=resultalldata['sum'][y]\n",
    "\n",
    "    newname=data.index.tolist()    \n",
    "    newname.append('stock')\n",
    "    newname.append('date')\n",
    "\n",
    "    X_train=np.array(a[newname][j:i])\n",
    "    Y_train=np.array(a['rise_fall'][j:i])\n",
    "    #第x个月，测试集\n",
    "    X_test=np.array(b[newname][x:y])\n",
    "    Y_test=np.array(b['rise_fall'][x:y])\n",
    "    X_train_scaled,X_test_scaled=X_train[:,:-3],X_test[:,:-3]\n",
    "    return X_train_scaled,X_test_scaled,Y_train,Y_test,X_test\n",
    "\n",
    "def change(data,n,m,M,date_list):\n",
    "    date=date_list[M:-4]\n",
    "    factor_df=pd.DataFrame(columns=date)\n",
    "    factor_df['stock']=list(month_alpha_factor_series[100].index)\n",
    "#     factor_df['stock']=data['stock']\n",
    "\n",
    "    for i,t in itertools.zip_longest(data,date):\n",
    "        temp=factor_df[['stock']]\n",
    "        temp[t]=np.nan\n",
    "        u=i.iloc[:,[n,m]]\n",
    "        u.columns=[t,'stock']\n",
    "        factor_Crash=pd.concat([u,temp],join='inner',ignore_index=True)\n",
    "        factor_Crash.sort_values(t,inplace=True)\n",
    "        factor_Crash.drop_duplicates(['stock'],inplace=True)\n",
    "        factor_Crash.sort_values('stock',inplace=True)\n",
    "        factor_Crash.reset_index(inplace=True)\n",
    "        factor_df[t]= factor_Crash[t]\n",
    "    factorF_df=factor_df.set_index(['stock'])\n",
    "    return factorF_df\n",
    "\n",
    "def changeindex1(data,M,date_list):\n",
    "    factor_df=change(data,0,1,M,date_list)\n",
    "    return  factor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 因子测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alphafactors.factorprepro_class as fp\n",
    "import alphafactors.factoranalyse as fa\n",
    "\n",
    "#因子处理(分成两种方向)\n",
    "def factor_analyse(name,factor):  # 0-positive , 1-negetive\n",
    "    factor_prepro_obj = fp.FactorPrePro(factor_name=name, factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    factor_test_obj = fa.FactorAnalyse(factor_name=name, factor_data_df=df, factor_dr=0)   # 0-positive , 1-negetive\n",
    "    factor_test_obj.run_analyse_new(start_date=dt.datetime(2009,1,23), universe='ZZ')\n",
    "    return factor_test_obj\n",
    "\n",
    "#因子测试画图显示\n",
    "def show1(factor_test_obj):\n",
    "    factor_test_obj.net_value_df.iloc[:,-3:].plot(figsize=(20,10))\n",
    "def show2(factor_test_obj):\n",
    "    factor_test_obj.factor_perform_df\n",
    "    return  factor_test_obj.factor_perform_df\n",
    "def show3(factor_test_obj):\n",
    "    factor_test_obj.factor_para_df\n",
    "    return  factor_test_obj.factor_para_df\n",
    "def show4(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df\n",
    "    return     factor_test_obj.port_perform_df\n",
    "def show5(factor_test_obj):\n",
    "    factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')\n",
    "    return factor_test_obj.port_perform_df['annual_return'].plot(kind='bar')   \n",
    "def show6(factor_test_obj):\n",
    "    factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')\n",
    "    return  factor_test_obj.factor_index_df['IC值'].plot(kind='bar', figsize=(20,10), color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 因子测试2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util.evalstat as evl\n",
    "                                     \n",
    "def factor_test_pre(factor):         #因子中性化预处理\n",
    "    factor_prepro_def stock_choice(data,num):                 #直接挑选概率值前100支股票，等权\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "        stock_series.loc[i]=pd.Series(index=[data[i].sort_values(ascending=False).head(num).index],data=1/num)\n",
    "    stock_choice_obj=factor_test(stock_series)\n",
    "    \n",
    "    return stock_choice_obj\n",
    "\n",
    "def stock_bench_ind(data,num):   #行业中性，基准权重后挑选100支股票\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "       set_date=i\n",
    "       stock_series[i]=get_industry_stock(data[i], set_date, stock_num=num)\n",
    "    stock_choice_obj =factor_test(stock_series)\n",
    "\n",
    "    return stock_choice_obj\n",
    "\n",
    "def factor_stock_choose(factor,num):\n",
    "    factor_obj=factor_test_pre(factor)   #做因子预处理\n",
    "    #等权选num支\n",
    "    samew_pre=stock_choice(factor_obj,num)\n",
    "    samew_unpre=stock_choice(factor,num)   #不做因子预处理，等权直接选100支\n",
    "    #不等权选num支\n",
    "    unw_pre=stock_bench_ind(factor_obj,num)\n",
    "    unw_unpre=stock_bench_ind(factor,num)\n",
    "    return samew_pre,samew_unpre,unw_pre,unw_unpreobj = fp.FactorPrePro(factor_name='factor_test', factor_data_df=factor, universe='ZZ', neutral_list=None)\n",
    "    factor_prepro_obj.run_process(start_date=max(factor.columns[0], dt.datetime(2007,1,5)), end_date=factor.columns[-1])\n",
    "    df = factor_prepro_obj.factor_pro_df\n",
    "    return df\n",
    "\n",
    "def factor_test(stock_weighted_series):\n",
    "    perform_obj=evl.PortPerform(port_series=stock_weighted_series,ret_type='open',fee=0.0035)\n",
    "    perform_obj.run()\n",
    "    return perform_obj\n",
    "\n",
    "def show01(perform_obj):\n",
    "    perform_obj.net_value_plot()        \n",
    "def show02(perform_obj):\n",
    "    perform_obj.get_strategy_perform() \n",
    "    return perform_obj.get_strategy_perform()      \n",
    "def show03(perform_obj):\n",
    "    perform_obj.get_avg_turnover()  \n",
    "    return perform_obj.get_avg_turnover()      \n",
    "def show04(perform_obj):\n",
    "    perform_obj.get_annual_perform()  \n",
    "    return  perform_obj.get_annual_perform()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 投资组合构建（2种：一种等权，一种不等权）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stock_choice(data,num):                 #直接挑选概率值前100支股票，等权\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "        stock_series.loc[i]=pd.Series(index=[data[i].sort_values(ascending=False).head(num).index],data=1/num)\n",
    "    stock_choice_obj=factor_test(stock_series)\n",
    "    \n",
    "    return stock_choice_obj\n",
    "\n",
    "def stock_bench_ind(data,num):   #行业中性，基准权重后挑选100支股票\n",
    "    stock_series= pd.Series()\n",
    "    for i in data.columns:\n",
    "       set_date=i\n",
    "       stock_series[i]=get_industry_stock(data[i], set_date, stock_num=num)\n",
    "    stock_choice_obj =factor_test(stock_series)\n",
    "\n",
    "    return stock_choice_obj\n",
    "\n",
    "def factor_stock_choose(factor,num):\n",
    "    factor_obj=factor_test_pre(factor)   #做因子预处理\n",
    "    #等权选num支\n",
    "    samew_pre=stock_choice(factor_obj,num)\n",
    "    samew_unpre=stock_choice(factor,num)   #不做因子预处理，等权直接选100支\n",
    "    #不等权选num支\n",
    "    unw_pre=stock_bench_ind(factor_obj,num)\n",
    "    unw_unpre=stock_bench_ind(factor,num)\n",
    "    return samew_pre,samew_unpre,unw_pre,unw_unpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基准行业权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_industry_df = dao.get_security_info('stock_industry_CS')\n",
    "stock_industry_list = dso.get_industry_classify('CS')\n",
    "stock_pool_df = dao.get_index_component_data('DEF')\n",
    "\n",
    "def get_bench_ind_weight(set_date, bench_code='ZZ500'):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "    # 基准行业权重\n",
    "    bench_component_df = dao.get_index_component_data(bench_code)\n",
    "    bench_series = pd.Series(bench_component_df[set_date].set_index('code')['weight'])\n",
    "    bench_series = bench_series / bench_series.sum()\n",
    "    bench_ind_weight_series = pd.Series(index=stock_industry_list)\n",
    "    for industry_name in stock_industry_list:\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        temp_series = bench_series.copy()\n",
    "        bench_ind_weight_series.loc[industry_name] = temp_series.reindex(ind_stock_list).sum()\n",
    "    bench_ind_weight_series.fillna(0, inplace=True)\n",
    "    return bench_ind_weight_series\n",
    "\n",
    "\n",
    "def get_industry_stock(stock_factor_series, set_date, stock_num=100):\n",
    "    industry_series = optool.get_series_from_df(data_df=stock_industry_df, set_date=set_date, axis=1).dropna()\n",
    "    stock_series = stock_pool_df[set_date]\n",
    "    stock_list = industry_series.index.intersection(stock_series.dropna().index).tolist()\n",
    "    industry_series = industry_series.loc[stock_list]\n",
    "\n",
    "    group_data = industry_series.index.groupby(industry_series)\n",
    "\n",
    "    # 基准行业权重\n",
    "    bench_ind_weight_series = get_bench_ind_weight(set_date=set_date)\n",
    "    bench_ind_num_series = round(bench_ind_weight_series * stock_num).astype(int)\n",
    "\n",
    "    port_series = pd.Series()\n",
    "    # 得到行业中性组合\n",
    "    for industry_name in stock_industry_list[:]:\n",
    "        if bench_ind_weight_series[industry_name] <= 0.0:\n",
    "            continue\n",
    "        ind_stock_list = group_data[industry_name]\n",
    "        ind_stock_series = pd.Series(stock_factor_series.loc[ind_stock_list]).reindex(ind_stock_list).sort_values(\n",
    "            ascending=False)\n",
    "\n",
    "        ind_stock_num = bench_ind_num_series[industry_name]\n",
    "        if ind_stock_num < 1:\n",
    "            ind_stock_num += 1\n",
    "\n",
    "        if ind_stock_series.shape[0] >= ind_stock_num:\n",
    "            xx = ind_stock_series.head(ind_stock_num)\n",
    "            temp_series = xx / xx.sum() * bench_ind_weight_series[industry_name]\n",
    "        else:\n",
    "            temp_series = ind_stock_series / ind_stock_series.sum() * bench_ind_weight_series[industry_name]\n",
    "\n",
    "            temp_series = pd.Series(index=ind_stock_series.index[:ind_stock_num], data=1.0 / ind_stock_num) * \\\n",
    "                          bench_ind_weight_series[industry_name]\n",
    "        port_series = port_series.append(temp_series)\n",
    "    return port_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
